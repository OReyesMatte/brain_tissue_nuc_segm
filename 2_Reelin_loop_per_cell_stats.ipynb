{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NVIDIA GeForce RTX 4090 on Platform: NVIDIA CUDA (2 refs)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import czifile\n",
    "import tifffile\n",
    "import pyclesperanto_prototype as cle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import check_filenames, segment_nuclei_2d, simulate_cytoplasm\n",
    "from skimage.measure import regionprops_table\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "\n",
    "cle.select_device(\"RTX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No files missing in images list.\n",
      "No files missing in rois list.\n"
     ]
    }
   ],
   "source": [
    "# Copy the path where your images are stored, ideally inside the raw_data directory\n",
    "directory_path = Path(\"./raw_data/Reelin\")\n",
    "roi_directory_path = Path(\"./raw_data/Reelin/ROI\")\n",
    "\n",
    "# Define the subdirectories containing your data\n",
    "subdirectories = [\"Contra\", \"Ipsi\", \"Sham\"]\n",
    "\n",
    "# Create empty lists to store all image filepaths and ROIs within the dataset directory\n",
    "images = []\n",
    "rois = []\n",
    "\n",
    "# Create an empty list to store all stats extracted from each image\n",
    "stats = []\n",
    "\n",
    "# Scan subdirectories and add paths to images fitting certain conditions\n",
    "for subdir in subdirectories:\n",
    "    # Construct the subdirectory path\n",
    "    image_path = directory_path / subdir\n",
    "    # Iterate through the .czi files in the subdirectories\n",
    "    for file_path in image_path.glob(\"*.czi\"):\n",
    "        # Remove unwanted images\n",
    "        if \"AWT\" not in str(file_path) and \"BWT\" not in str(file_path):\n",
    "            images.append(str(file_path))\n",
    "\n",
    "# Scan ROI directory and add paths to the list\n",
    "for file_path in roi_directory_path.glob(\"*.tif\"):\n",
    "    # Remove unwanted images\n",
    "        if \"AWT\" not in str(file_path) and \"BWT\" not in str(file_path):\n",
    "            rois.append(str(file_path))\n",
    "\n",
    "# Check if there is any missing ROI or image file in their corresponding directories\n",
    "check_filenames(images, rois)\n",
    "\n",
    "# Extract filenames without extensions and sort the lists so they appear in the same order\n",
    "images_sorted = sorted(images, key=lambda x: Path(x).stem)\n",
    "rois_sorted = sorted(rois, key=lambda x: Path(x).stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path, roi_path in tqdm(zip(images_sorted, rois_sorted)):\n",
    "\n",
    "    # Read path storing raw image and extract filename\n",
    "    file_path = Path(image_path)\n",
    "    filename = file_path.stem\n",
    "\n",
    "    # Get rid of double spaces in the filename\n",
    "    filename = filename.replace(\"  \", \" \")\n",
    "\n",
    "    # Extract experimental conditions from the filename\n",
    "    descriptors = filename.split(\" \")\n",
    "    condition = descriptors[0]\n",
    "\n",
    "    try:\n",
    "        # Convert strings to int\n",
    "        condition_nr = int(descriptors[1])\n",
    "        brain_location = descriptors[2]\n",
    "        mouse_id = int(descriptors[4])\n",
    "        slide = int(descriptors[5][-1])\n",
    "        tech_replica = int(descriptors[-1])\n",
    "\n",
    "    except ValueError:\n",
    "        # In the case of erroneous filenaming add info as strings\n",
    "        condition_nr = descriptors[1]\n",
    "        brain_location = descriptors[2]\n",
    "        mouse_id = descriptors[4]\n",
    "        slide = descriptors[5][-1]\n",
    "        tech_replica = descriptors[-1]\n",
    "\n",
    "    # Read image and ROI files into Numpy arrays\n",
    "    img = czifile.imread(image_path)\n",
    "    roi = tifffile.imread(roi_path)\n",
    "\n",
    "    # Remove singleton dimensions and perform MIP on input image\n",
    "    img = img.squeeze()\n",
    "    img_mip = np.max(img, axis=1)\n",
    "\n",
    "    # Perform MIP for the region of interest\n",
    "    roi_mip = np.max(roi, axis=0)\n",
    "\n",
    "    # We will create a mask where label_mip is greater than or equal to 1\n",
    "    mask = roi_mip >= 1\n",
    "\n",
    "    # Apply the mask to img_mip\n",
    "    masked_img = np.where(mask, img_mip, 0)\n",
    "\n",
    "    # Extract each of the channels separately\n",
    "    neun_mip = masked_img[0, :, :]\n",
    "    reelin_mip = masked_img[1, :, :]\n",
    "    gad67_mip = masked_img[2, :, :]\n",
    "    nuclei_mip = masked_img[3, :, :]\n",
    "\n",
    "    # Segment nuclei inside the ROI\n",
    "    nuclei_labels = segment_nuclei_2d(nuclei_mip)\n",
    "\n",
    "    # Simulate a cytoplasm by dilating the nuclei and substracting the nuclei mask afterwards\n",
    "    cytoplasm = simulate_cytoplasm(nuclei_labels, dilation_radius = 2, erosion_radius = 0)\n",
    "\n",
    "    # Create a dictionary containing all image descriptors\n",
    "    descriptor_dict = {\n",
    "                \"filename\": filename,\n",
    "                \"condition\": condition,\n",
    "                \"condition_nr\": condition_nr,\n",
    "                \"brain_location\": brain_location,\n",
    "                \"mouse_id\": mouse_id,\n",
    "                \"slide_nr\": slide,\n",
    "                \"tech_replica\": tech_replica,\n",
    "                }\n",
    "    \n",
    "    # List to hold the dataframes\n",
    "    props_list = []\n",
    "\n",
    "    # Extract intensity information from each marker channel\n",
    "    neun_props = regionprops_table(label_image=nuclei_labels,\n",
    "                                intensity_image=neun_mip,\n",
    "                                properties=[\"label\", \"intensity_mean\", \"area\"])\n",
    "\n",
    "    reelin_props = regionprops_table(label_image=cytoplasm,\n",
    "                                intensity_image=reelin_mip,\n",
    "                                properties=[\"label\", \"intensity_mean\", \"area\"])\n",
    "\n",
    "    gad67_props = regionprops_table(label_image=cytoplasm,\n",
    "                                intensity_image=gad67_mip,\n",
    "                                properties=[\"label\", \"intensity_mean\"])\n",
    "\n",
    "    # Convert to dataframe\n",
    "    neun_props_df = pd.DataFrame(neun_props)\n",
    "    reelin_props_df = pd.DataFrame(reelin_props)\n",
    "    gad67_props_df = pd.DataFrame(gad67_props)\n",
    "\n",
    "    # Rename intensity_mean column to indicate the specific image\n",
    "    neun_props_df.rename(columns={\"intensity_mean\": f\"neun_intensity_mean\"}, inplace=True)\n",
    "    reelin_props_df.rename(columns={\"intensity_mean\": f\"reelin_intensity_mean\"}, inplace=True)\n",
    "    gad67_props_df.rename(columns={\"intensity_mean\": f\"gad67_intensity_mean\"}, inplace=True)\n",
    "    neun_props_df.rename(columns={\"area\": f\"nuclei_area\"}, inplace=True)\n",
    "    reelin_props_df.rename(columns={\"area\": f\"cyto_area\"}, inplace=True)\n",
    "\n",
    "    # Append to list\n",
    "    props_list.append(neun_props_df)\n",
    "    props_list.append(reelin_props_df)\n",
    "    props_list.append(gad67_props_df)\n",
    "\n",
    "    # Merge all dataframes on the \"label\" column\n",
    "\n",
    "    # Initialize the df with the first df in the list\n",
    "    props_df = props_list[0]\n",
    "    # Start looping from the second df in the list\n",
    "    for df in props_list[1:]:\n",
    "        props_df = props_df.merge(df, on=\"label\")\n",
    "\n",
    "    # Add each key-value pair from descriptor_dict to props_df\n",
    "    for key, value in descriptor_dict.items():\n",
    "        props_df[key] = value\n",
    "\n",
    "    stats.append(props_df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate list of dataframes into a single final df\n",
    "final_df = pd.concat(stats)\n",
    "\n",
    "# Perform k-means clustering with 3 clusters (no_signal, low_neun and high_neun)\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "final_df['neun+_cluster'] = kmeans.fit_predict(final_df[['neun_intensity_mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'results' folder in the root directory\n",
    "results_folder = 'results'\n",
    "\n",
    "try:\n",
    "    os.makedirs(results_folder)\n",
    "    print(f\"'{results_folder}' folder created successfully.\")\n",
    "except FileExistsError:\n",
    "    print(f\"'{results_folder}' folder already exists.\")\n",
    "\n",
    "# Save the df containing per_label results into a CSV file\n",
    "final_df.to_csv('./results/Reelin_per_label_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microglia_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
