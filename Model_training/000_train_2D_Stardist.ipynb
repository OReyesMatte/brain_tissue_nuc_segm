{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please shutdown all other training/prediction notebooks before running this notebook (as those might occupy the GPU memory otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import napari\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from csbdeep.utils import normalize\n",
    "\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents\n",
    "from stardist.matching import matching_dataset\n",
    "from stardist.models import Config2D, StarDist2D\n",
    "\n",
    "from utils_training_stardist import process_images, fix_overlapping_labels, ignore_xy_border_labels, plot_img_label, augmenter_2D\n",
    "\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data loading and normalization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to the disk location where your images and ground truth labels (masks) are located\n",
    "X = sorted(glob('../training_data/thick_brain_Nikon_dagnysd_0.5/X(512x512)/*.tif'))\n",
    "Y = sorted(glob('../training_data/thick_brain_Nikon_dagnysd_0.5/y(512x512)/*.tif'))\n",
    "\n",
    "# Set a slicing factor for training a model using compressed versions of your images (i.e. 2 or 4)\n",
    "slicing_factor = None\n",
    "\n",
    "# Did you allow overlapping labels in Labkit? Set fix labels to True if you need to get rid of overlapping nuclei labels. False by default.\n",
    "fix_labels = True\n",
    "\n",
    "# Ignore labels touching the edge of the annotated image during training?\n",
    "ignore_on_edges = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is provided via a list of Numpy arrays, it consists of pairs of input images (X) and label (Y) instances\n",
    "X = process_images(X, slicing_factor)\n",
    "Y = process_images(Y, slicing_factor)\n",
    "\n",
    "# Perform MIP of input images and labels if these are a 3D stack\n",
    "X = [np.max(x, axis=0) for x in tqdm(X) if len(x.shape) ==  3]\n",
    "Y = [np.max(y, axis=0) for y in tqdm(Y) if len(y.shape) ==  3]\n",
    "\n",
    "# Normalize images and fill small label holes if present\n",
    "axis_norm = (0,1)   # normalize channels independently\n",
    "print(\"Normalizing input images...\")\n",
    "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "print(\"\\nFilling label holes...\")\n",
    "Y = [fill_label_holes(y) for y in tqdm(Y)]\n",
    "\n",
    "# Remove overlapping labels if present\n",
    "if fix_labels:\n",
    "    print(\"\\nFixing overlapping labels...\")\n",
    "    Y = [fix_overlapping_labels(y) for y in tqdm(Y)]\n",
    "\n",
    "# Ignore labels on edges during training\n",
    "if ignore_on_edges:\n",
    "    print(\"\\nRemoving (ignoring) xy edge touching labels...\")\n",
    "    Y = [ignore_xy_border_labels(y) for y in tqdm(Y)]\n",
    "\n",
    "\n",
    "# Perform an 80/20 training/validation split \n",
    "X_trn, X_val, Y_trn, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(f\"\\nNumber of images: {len(X)}\")\n",
    "print(f\"- Training: {len(X_trn)}\")\n",
    "print(f\"- Validation: {len(X_val)}\")\n",
    "print(f\"\\nSlicing factor applied: {slicing_factor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Image and ground truth visualization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore individual image/label pairs in Napari by setting an index value\n",
    "index = 0\n",
    "\n",
    "viewer = napari.Viewer(ndisplay=2)\n",
    "viewer.add_image(X_trn[index])\n",
    "viewer.add_labels(Y_trn[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model Configuration</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 is a good default choice (see 1_data.ipynb)\n",
    "n_rays = 32\n",
    "\n",
    "# Use OpenCL-based computations for data generator during training (requires 'gputools') - Not implemented\n",
    "use_gpu = False\n",
    "\n",
    "# Predict on subsampled grid for increased efficiency and larger field of view\n",
    "grid = (2,2)\n",
    "\n",
    "conf = Config2D (\n",
    "    n_rays             = n_rays,\n",
    "    grid             = grid, # You might need to manually adjust if the object size is larger than the FOV of the network (i.e. (1, 4, 4))\n",
    "    use_gpu          = use_gpu,\n",
    "    n_channel_in     = 1,\n",
    "    train_patch_size = (512,512), # Adjust for your data (make patch size as large as possible)\n",
    "    train_batch_size = 2,\n",
    "    train_epochs=300,\n",
    ")\n",
    "print(conf)\n",
    "vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarDist2D(conf, name=f'2D_brain_Nikon_dagnysd_0.5_sf_{slicing_factor}', basedir='../3D_Stardist/stardist_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the neural network has a large enough field of view to see up to the boundary of most objects.\n",
    "\n",
    "median_size = calculate_extents(Y, np.median)\n",
    "fov = np.array(model._axes_tile_overlap('YX'))\n",
    "print(f\"median object size:      {median_size}\")\n",
    "print(f\"network field of view :  {fov}\")\n",
    "if any(median_size > fov):\n",
    "    print(\"WARNING: median object size larger than field of view of the neural network. Increase the grid parameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Augmentation and Training</h3>\n",
    "\n",
    "You can define a function/callable that applies augmentation to each batch of the data generator (see <code>utils_training_stardist.py</code>).\n",
    "We here use an <code>augmenter</code> that applies random rotations, flips, and intensity changes, which are typically sensible for (3D) microscopy images (but you can disable augmentation by setting <code>augmenter = None</code>).\n",
    "\n",
    "You can monitor the progress during training in a separate JN by launching a Tensorboard instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter_2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Threshold optimization</h3>\n",
    "\n",
    "While the default values for the probability and non-maximum suppression thresholds already yield good results in many cases, we still recommend to adapt the thresholds to your data. The optimized threshold values are saved to disk and will be automatically loaded with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimize_thresholds(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluation and Detection Performance</h3>\n",
    "\n",
    "Besides the losses and metrics during training, we can also quantitatively evaluate the actual detection/segmentation performance on the validation data by considering objects in the ground truth to be correctly matched if there are predicted objects with overlap (here [intersection over union (IoU)](https://en.wikipedia.org/wiki/Jaccard_index)) beyond a chosen IoU threshold $\\tau$.\n",
    "\n",
    "The corresponding matching statistics (average overlap, accuracy, recall, precision, etc.) are typically of greater practical relevance than the losses/metrics computed during training (but harder to formulate as a loss function). \n",
    "The value of $\\tau$ can be between 0 (even slightly overlapping objects count as correctly predicted) and 1 (only pixel-perfectly overlapping objects count) and which $\\tau$ to use depends on the needed segmentation precision/application.\n",
    "\n",
    "Please see `help(matching)` for definitions of the abbreviations used in the evaluation below and see the Wikipedia page on [Sensitivity and specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity) for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_pred = [model.predict_instances(x, n_tiles=model._guess_n_tiles(x), show_tile_progress=False)[0]\n",
    "              for x in tqdm(X_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(0,len(X_val)):\n",
    "    # Plot a Ground Truth (GT) / Prediction example\n",
    "    plot_img_label(X_val[index],Y_val[index], lbl_title=\"label GT (XY slice)\")\n",
    "    plot_img_label(X_val[index],Y_val_pred[index], lbl_title=\"label Pred (XY slice)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose several IoU thresholds $\\tau$ that might be of interest and for each compute matching statistics for the validation data.\n",
    "taus = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "stats = [matching_dataset(Y_val, Y_val_pred, thresh=t, show_progress=False) for t in tqdm(taus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Print all available matching statistics for tau=0.7\n",
    "stats[taus.index(0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the matching statistics and the number of true/false positives/negatives as a function of the IoU threshold\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "for m in ('precision', 'recall', 'accuracy', 'f1', 'mean_true_score', 'mean_matched_score', 'panoptic_quality'):\n",
    "    ax1.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax1.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax1.set_ylabel('Metric value')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "for m in ('fp', 'tp', 'fn'):\n",
    "    ax2.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax2.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax2.set_ylabel('Number #')\n",
    "ax2.grid()\n",
    "ax2.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_nuc_stardist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
