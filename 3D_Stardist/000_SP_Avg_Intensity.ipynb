{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3D stack - Single image - Marker+ based on average intensity</h2>\n",
    "\n",
    "The following notebook is able to process a 3D stack (.czi or .nd2 files) and allows you to:\n",
    "\n",
    "1. Inspect your images in Napari.\n",
    "2. Define ROIs if needed.\n",
    "3. Read previously defined ROIs, if not present, full image is analyzed.\n",
    "4. Read previously predicted nuclei labels, if not present, generates them.\n",
    "5. Plot cytoplasmic and nuclear average intensities of all markers in all ROIs to later on set a threshold for classification.\n",
    "6. Extract numbers of cells positive for all marker based on signal average intensity within the nuclear or cytoplasmic compartments (using a user-defined min-max range).\n",
    "6. Display positive cells in Napari.\n",
    "7. Extract and save per label per ROI per marker data in a .csv file (filename_per_label_avg_int.csv).\n",
    "8. Extract and save number of positive cells in a .csv file (SP_marker_+_label_avg_int.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tifffile\n",
    "import napari\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.measure import regionprops_table\n",
    "import plotly.express as px\n",
    "from stardist.models import StarDist3D\n",
    "from utils_stardist import get_gpu_details, list_images, read_image, extract_nuclei_stack, maximum_intensity_projection, save_rois, simulate_cytoplasm_chunked_3d, segment_nuclei_3d\n",
    "\n",
    "get_gpu_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define the directory for your images (.nd2 or .czi files) and cell marker info</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the path where your images are stored, you can use absolute or relative paths to point at other disk locations\n",
    "directory_path = Path(\"../raw_data/test_data\")\n",
    "\n",
    "# Define the channels you want to analyze using the following structure:\n",
    "# markers = [(channel_name, channel_nr, cellular_location),(..., ..., ...)]\n",
    "# Remember in Python one starts counting from 0, so your first channel will be 0\n",
    "# markers = [(\"ki67\", 0, \"nucleus\"), (\"neun\", 1, \"nucleus\"), (\"calbindin\", 2, \"cytoplasm\")]\n",
    "markers = [(\"ki67\", 0, \"nucleus\"), (\"neun\", 1, \"nucleus\"), (\"calbindin\", 2, \"cytoplasm\")]\n",
    "\n",
    "# Iterate through the .czi and .nd2 files in the raw_data directory\n",
    "images = list_images(directory_path)\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Open each image in the directory</h3>\n",
    "You can do so by changing the number within the brackets below <code>image = images[0]</code>. Make sure to input the same <code>slicing factor</code> you used when generating nuclei predictions. \n",
    "\n",
    "If you have not generated nuclei predictions already, input <code>nuclei_channel</code>, <code>cellpose_nuclei_diameter</code> and <code>gaussian_sigma</code> values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore each image to analyze (0 defines the first image in the directory)\n",
    "image = images[0]\n",
    "\n",
    "# Image size reduction to improve processing times (slicing, not lossless compression)\n",
    "slicing_factor = None # Use 2 or 4 for compression (None for lossless)\n",
    "\n",
    "# Define the nuclei and markers of interest channel order ('Remember in Python one starts counting from zero')\n",
    "nuclei_channel = 3\n",
    "\n",
    "n_tiles=(6,6,3)\n",
    "\n",
    "# Segmentation type (\"2D\" or \"3D\"). \n",
    "# 2D takes a z-stack as input, performs MIP (Maximum Intensity Projection) and predicts nuclei from the resulting projection (faster, useful for single layers of cells)\n",
    "# 3D is more computationally expensive. Predicts 3D nuclear volumes, useful for multilayered structures\n",
    "segmentation_type = \"3D\"\n",
    "\n",
    "# Nuclear segmentation model type (\"Stardist\")\n",
    "# Choose your Stardist fine-tuned model (model_name) from stardist_models folder\n",
    "model_name = \"MEC0.1\"\n",
    "\n",
    "# Model loading \n",
    "model = StarDist3D(None, name=model_name, basedir='stardist_models') \n",
    "\n",
    "# Generate maximum intensity projection and extract filename\n",
    "img, filename = read_image (image, slicing_factor)\n",
    "\n",
    "# Slice the nuclei stack\n",
    "nuclei_img = extract_nuclei_stack(img, nuclei_channel)\n",
    "\n",
    "# Generate maximum intensity projection \n",
    "img_mip = maximum_intensity_projection(img)\n",
    "\n",
    "# Show image in Napari\n",
    "viewer = napari.Viewer(ndisplay=2)\n",
    "viewer.add_image(img_mip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Label your regions of interest in Napari and explore the signal of your marker of interest</h3>\n",
    "\n",
    "Make sure to set <code>n edit dim = 3</code> so the label propagates across all channels. Name your regions of interest as i.e. <code>DG</code>, <code>CA1</code>, <code>CA3</code> or <code>HIPPO</code>. If you do not draw any ROI the entire image will be analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video controls>\n",
    "  <source src=\"../assets/napari_labels.mp4\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save user-defined label ROIs as .tiff files</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_rois(viewer, directory_path, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Extract average intensities of markers within each defined cell compartment and ROI</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 3D-stack into Napari\n",
    "if segmentation_type == \"3D\":\n",
    "    # Remove the 'img_mip' layer if it exists\n",
    "    if 'img_mip' in viewer.layers:\n",
    "        viewer.layers.remove('img_mip')\n",
    "    # Add the 'img' stack\n",
    "    viewer.add_image(img)\n",
    "\n",
    "# Construct ROI and nuclei predictions paths from directory_path above\n",
    "roi_path = directory_path / \"ROIs\"\n",
    "nuclei_preds_path =  directory_path / \"nuclei_preds\" / segmentation_type / model_name\n",
    "\n",
    "# Extract the experiment name from the data directory path\n",
    "experiment_id = directory_path.name\n",
    "\n",
    "# List of subfolder names\n",
    "try:\n",
    "    roi_names = [folder.name for folder in roi_path.iterdir() if folder.is_dir()]\n",
    "except FileNotFoundError:\n",
    "    roi_names = [\"full_image\"]\n",
    "\n",
    "print(f\"The following regions of interest will be analyzed: {roi_names}\")\n",
    "\n",
    "# Initialize an empty list to hold the extracted dataframes on a per ROI basis\n",
    "per_roi_props = []\n",
    "\n",
    "for roi_name in tqdm(roi_names):\n",
    "    print(f\"\\nAnalyzing ROI: {roi_name}\")\n",
    "\n",
    "    # Initialize an empty list to hold the extracted dataframes on a per channel basis\n",
    "    props_list = []\n",
    "\n",
    "    # Read the user defined ROIs, in case of full image analysis generate a label covering the entire image\n",
    "    try:\n",
    "        # Read previously defined ROIs\n",
    "        user_roi = tifffile.imread(roi_path / roi_name / f\"{filename}.tiff\")\n",
    "    except FileNotFoundError:\n",
    "        # Extract the xy dimensions of the input image \n",
    "        img_shape = img.shape\n",
    "        img_xy_dims = img_shape[-2:]\n",
    "\n",
    "        # Create a label covering the entire image\n",
    "        user_roi = np.ones(img_xy_dims).astype(np.uint8)\n",
    " \n",
    "    # Read previously predicted nuclei labels, if not present generate nuclei predictions and save them\n",
    "    try:\n",
    "        # Read the nuclei predictions per ROI\n",
    "        nuclei_labels = tifffile.imread(nuclei_preds_path / roi_name / f\"{filename}.tiff\")\n",
    "        print(f\"Pre-computed nuclei labels found for {filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Generating nuclei labels for {filename}\")\n",
    "\n",
    "        # We will create a mask where roi is greater than or equal to 1\n",
    "        mask = (user_roi >= 1).astype(np.uint8)\n",
    "\n",
    "        # 3D segmentation logic, extend 2D mask across the entire stack volume\n",
    "        if segmentation_type == \"3D\":\n",
    "            # Extract the number of z-slices to extend the mask\n",
    "            slice_nr = img.shape[1]\n",
    "            # Extend the mask across the entire volume\n",
    "            mask = np.tile(mask, (slice_nr, 1, 1))\n",
    "            # Apply the mask to nuclei_img, setting all other pixels to 0\n",
    "            masked_nuclei_img = np.where(mask, nuclei_img, 0)\n",
    "        else:\n",
    "            # Apply the mask to nuclei_img, setting all other pixels to 0\n",
    "            masked_nuclei_img = np.where(mask, nuclei_img, 0)\n",
    "\n",
    "        # Segment nuclei and return labels\n",
    "        nuclei_labels = segment_nuclei_3d(masked_nuclei_img, model, n_tiles)\n",
    "\n",
    "        # Save nuclei labels as .tiff files to reuse them later\n",
    "        try:\n",
    "            os.makedirs(nuclei_preds_path / roi_name, exist_ok=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating directory {nuclei_preds_path / roi_name}: {e}\")\n",
    "\n",
    "        # Construct path to store\n",
    "        path_to_store = nuclei_preds_path / roi_name / f\"{filename}.tiff\"\n",
    "        print(f\"Saving nuclei labels to {path_to_store}\")\n",
    "        try:\n",
    "            tifffile.imwrite(path_to_store, nuclei_labels)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving file {path_to_store}: {e}\")\n",
    "\n",
    "    # Add the predicted nuclei as labels into Napari\n",
    "    viewer.add_labels(nuclei_labels, name=f\"{roi_name}_nuclei\")\n",
    "\n",
    "    # Add the ROIs as labels into Napari\n",
    "    viewer.add_labels(user_roi, name=f\"{roi_name}_ROI\", opacity=0.4)\n",
    "\n",
    "    # Create a dictionary containing all image descriptors\n",
    "    descriptor_dict = {\"filename\": filename, \"ROI\": roi_name}\n",
    "\n",
    "    # Loop through each channel and extract the average intensity within either nuclei or cytoplasmic regions\n",
    "    for channel_name, ch_nr, location in tqdm(markers):\n",
    "        print(f\"Analyzing channel: {channel_name}\")\n",
    "\n",
    "        if location == \"cytoplasm\":\n",
    "            print(f\"Generating cytoplasm labels for: {channel_name}\")\n",
    "            # Simulate a cytoplasm by dilating the nuclei and subtracting the nuclei mask afterwards\n",
    "            cytoplasm_labels = simulate_cytoplasm_chunked_3d(nuclei_labels, dilation_radius=2, erosion_radius=0, chunk_size=(1, 1024, 1024))\n",
    "            # Add the predicted cytoplasm labels into Napari\n",
    "            viewer.add_labels(cytoplasm_labels, name=f\"{roi_name}_cytoplasm\")\n",
    "\n",
    "            # Extract intensity information from each marker channel\n",
    "            props = regionprops_table(label_image=cytoplasm_labels,\n",
    "                                      intensity_image=img[ch_nr],\n",
    "                                      properties=[\"label\", \"intensity_mean\"])\n",
    "        elif location == \"nucleus\":\n",
    "            # Extract intensity information from each marker channel\n",
    "            props = regionprops_table(label_image=nuclei_labels,\n",
    "                                      intensity_image=img[ch_nr],\n",
    "                                      properties=[\"label\", \"intensity_mean\"])\n",
    "\n",
    "        # Convert to dataframe\n",
    "        props_df = pd.DataFrame(props)\n",
    "\n",
    "        # Rename intensity_mean column to indicate the specific image\n",
    "        props_df.rename(columns={\"intensity_mean\": f\"{location}_{channel_name}_avg_int\"}, inplace=True)\n",
    "\n",
    "        # Append each props_df to props_list\n",
    "        props_list.append(props_df)\n",
    "\n",
    "    # Initialize the df with the first df in the list\n",
    "    props_df = props_list[0]\n",
    "    # Start looping from the second df in the list\n",
    "    for df in props_list[1:]:\n",
    "        props_df = props_df.merge(df, on=\"label\")\n",
    "\n",
    "    # Add each key-value pair from descriptor_dict to props_df at the specified position\n",
    "    insertion_position = 0\n",
    "    for key, value in descriptor_dict.items():\n",
    "        props_df.insert(insertion_position, key, value)\n",
    "        insertion_position += 1  # Increment position to maintain the order of keys in descriptor_dict\n",
    "\n",
    "    # Append each props_df to per_roi_props\n",
    "    per_roi_props.append(props_df)\n",
    "\n",
    "# Concatenate all per_roi_props into final_df\n",
    "final_df = pd.concat(per_roi_props, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save per label per ROI per marker data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'results' folder in the root directory\n",
    "results_folder = Path(\"results\") / experiment_id / segmentation_type / model_name\n",
    "\n",
    "try:\n",
    "    os.makedirs(results_folder)\n",
    "    print(f\"'{results_folder}' folder created successfully.\")\n",
    "except FileExistsError:\n",
    "    print(f\"'{results_folder}' folder already exists.\")\n",
    "\n",
    "# Save the df containing per_label results into a CSV file\n",
    "final_df.to_csv(results_folder / f'{filename}_per_label_avg_int.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plot average intensities</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all column names in 'final_df' that contain the substring 'avg_int'\n",
    "avg_int_columns = [col for col in final_df.columns if 'avg_int' in col]\n",
    "\n",
    "# Loop over all extracted channel average intensities\n",
    "for column_name in avg_int_columns:\n",
    "\n",
    "    # Plot the average_intensity distribution in order to make an informed decision on the threshold\n",
    "    for roi_name in roi_names:\n",
    "\n",
    "        # Filter rows in final_df where ROI matches roi_name \n",
    "        filtered_df = final_df[(final_df[\"ROI\"] == roi_name)]\n",
    "\n",
    "        # Get the values of the 'label' column in filtered_df as a list\n",
    "        avg_int_values = filtered_df[column_name]\n",
    "\n",
    "        # Plot a histogram with 256 bins and a title indicating the column and ROI\n",
    "        fig = px.histogram(avg_int_values, nbins=256, \n",
    "                           title=f\"{column_name}_in_{roi_name}\",\n",
    "                           labels={'value': column_name, 'count': 'Frequency'},\n",
    "                           range_x=[0, 255])\n",
    "        \n",
    "        # Show the plot\n",
    "        fig.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Select cells positive for a marker based on average intensity</h3>\n",
    "\n",
    "Define in <code>min_max_per_marker</code> the <code>marker</code> you want to use to define your cell populations of interest, the <code>min_max</code> range of avg_int and the <code>population</code> name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can choose markers from the following list\n",
    "markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with min_max_avg_int for each channel\n",
    "# Give the possibility to define populations for the same marker (i.e. neun high and neun low)\n",
    "# max_values are set to 255 since the test input images are 8-bit, higher bit depths can result in higher max avg_int values\n",
    "\n",
    "min_max_per_marker = [{\"marker\": \"ki67\", \"min_max\": (110,255), \"population\":\"ki67\"},\n",
    "                      {\"marker\": \"neun\", \"min_max\": (20,80), \"population\":\"neun_low\"},\n",
    "                      {\"marker\": \"neun\", \"min_max\": (80,255), \"population\":\"neun_high\"},\n",
    "                      {\"marker\": \"calbindin\", \"min_max\": (40,255), \"population\":\"calbindin\"},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store all stats extracted from each image\n",
    "stats = []\n",
    "\n",
    "for marker_analysis in min_max_per_marker:\n",
    "\n",
    "    marker = marker_analysis[\"marker\"]\n",
    "    min_max_avg_int = marker_analysis[\"min_max\"]\n",
    "    population = marker_analysis[\"population\"]\n",
    "\n",
    "    # Retrieve the column name from which the avg_int values should be read\n",
    "    for column in avg_int_columns:\n",
    "        if marker in column:\n",
    "            column_name = column\n",
    "\n",
    "    for roi_name in roi_names:\n",
    "\n",
    "        # Initialize an empty list to hold the extracted dataframes on a per channel basis\n",
    "        props_list = []\n",
    "\n",
    "        # Retrieve the first and second values (channel and location) of the corresponding tuple in markers\n",
    "        for item in markers:\n",
    "            if item[0] == marker:\n",
    "                channel = item[1]\n",
    "                location = item[2]\n",
    "                break  # Stop searching once the marker is found\n",
    "\n",
    "        # Read the nuclei predictions per ROI\n",
    "        nuclei_labels = tifffile.imread(nuclei_preds_path / roi_name / f\"{filename}.tiff\")\n",
    "\n",
    "        # Filter rows in final_df where ROI matches roi_name and column_name is within min < avg_int <= max values.\n",
    "        filtered_df = final_df[(final_df[\"ROI\"] == roi_name) & (final_df[column_name] > min_max_avg_int[0]) & (final_df[column_name] <= min_max_avg_int[1])]\n",
    "\n",
    "        # Get the values of the 'label' column in filtered_df as a list\n",
    "        label_values = filtered_df[\"label\"].tolist()\n",
    "\n",
    "        # Create a boolean mask where each element is True if the corresponding value in 'nuclei_labels' \n",
    "        # is found in 'label_values', and False otherwise\n",
    "        mask = np.isin(nuclei_labels, label_values)\n",
    "\n",
    "        # Use the mask to set values in 'nuclei_labels' that are not in 'label_values' to 0,\n",
    "        # creating a new array 'filtered_labels' with only the specified values retained\n",
    "        filtered_labels = np.where(mask, nuclei_labels, 0)\n",
    "\n",
    "        viewer.add_labels(filtered_labels, name=f\"{population}_+_in_{roi_name}\")\n",
    "\n",
    "        # Extract your information of interest\n",
    "        total_nuclei = len(np.unique(nuclei_labels)) - 1\n",
    "        marker_pos_nuclei = len(np.unique(filtered_labels)) - 1\n",
    "\n",
    "        # Calculate \"%_marker+_cells\" and avoid division by zero errors\n",
    "        try:\n",
    "            perc_marker_pos_cells = (marker_pos_nuclei * 100) / total_nuclei\n",
    "        except ZeroDivisionError:\n",
    "            perc_marker_pos_cells = 0\n",
    "\n",
    "        # Create a dictionary containing all extracted info per masked image\n",
    "        stats_dict = {\n",
    "                    \"filename\": filename,\n",
    "                    \"ROI\": roi_name,\n",
    "                    \"based_on\": column_name,\n",
    "                    \"marker\": marker,\n",
    "                    \"population\":population,\n",
    "                    \"marker_ch\": channel,\n",
    "                    \"location\": location,\n",
    "                    \"min_max_avg_int\": min_max_avg_int,\n",
    "                    \"total_nuclei\": total_nuclei,\n",
    "                    \"marker+_nuclei\": marker_pos_nuclei,\n",
    "                    \"%_marker+_cells\": perc_marker_pos_cells,\n",
    "                    \"slicing_factor\": slicing_factor\n",
    "                    }\n",
    "        \n",
    "        # Append the current data point to the stats_list\n",
    "        stats.append(stats_dict)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save number of positive cells based on each marker</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'results' folder in the root directory\n",
    "results_folder = Path(\"results\") / experiment_id / segmentation_type / model_name\n",
    "\n",
    "# Create the necessary folder structure if it does not exist\n",
    "try:\n",
    "    os.mkdir(str(results_folder))\n",
    "    print(f\"Output folder created: {results_folder}\")\n",
    "except FileExistsError:\n",
    "    print(f\"Output folder already exists: {results_folder}\")\n",
    "\n",
    "# Transform into a dataframe to store it as .csv later\n",
    "df = pd.DataFrame(stats)\n",
    "\n",
    "# Define the .csv path\n",
    "csv_path = results_folder / f\"SP_marker_+_label_avg_int.csv\"\n",
    "\n",
    "# Append to the .csv with new data points each round\n",
    "df.to_csv(csv_path, mode=\"a\", index=False, header=not os.path.isfile(csv_path))\n",
    "\n",
    "# Show the updated .csv \n",
    "csv_df = pd.read_csv(csv_path)\n",
    "\n",
    "csv_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_nuc_stardist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
