{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3D stack - Batch Processing - Marker+ based on colocalization</h2>\n",
    "\n",
    "The following notebook is able to process a 3D stack (.czi or .nd2 files) into a MIP and allows you to:\n",
    "\n",
    "1. Read previously defined ROIs, if not present, full image is analyzed.\n",
    "2. Read previously predicted nuclei labels, if not present, generates them.\n",
    "3. Extract numbers of cells positive for a marker based on colocalization (using a user-defined threshold).\n",
    "4. Save number and % of positive cells in a .csv file (BP_marker_+_label_coloc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tifffile\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stardist.models import StarDist3D\n",
    "import pyclesperanto_prototype as cle\n",
    "from utils_stardist import get_gpu_details, list_images, read_image, extract_nuclei_stack, get_stardist_model, simulate_cytoplasm_chunked_3d, simulate_cell_chunked_3d, simulate_cytoplasm, simulate_cell, segment_marker_positive_labels, segment_nuclei\n",
    "\n",
    "get_gpu_details()\n",
    "cle.select_device(\"RTX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define the directory where your images are stored (.nd2 or .czi files)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the path where your images are stored, you can use absolute or relative paths to point at other disk locations\n",
    "directory_path = Path(\"../raw_data/test_data\")\n",
    "\n",
    "# Define the channels you want to analyze using the following structure:\n",
    "# markers = [(channel_name, channel_nr, cellular_location),(..., ..., ...)]\n",
    "# cellular locations can be \"nucleus\", \"cytoplasm\" or \"cell\" (cell being the sum volume of nucleus and cytoplasm)\n",
    "# Remember in Python one starts counting from 0, so your first channel will be 0\n",
    "# i.e. markers = [(\"ki67\", 0, \"nucleus\"), (\"neun\", 1, \"cell\"), (\"calbindin\", 2, \"cytoplasm\")]\n",
    "markers = [(\"ki67\", 0, \"nucleus\"), (\"neun\", 1, \"cell\"), (\"calbindin\", 2, \"cytoplasm\")]\n",
    "\n",
    "# Iterate through the .czi and .nd2 files in the directory\n",
    "images = list_images(directory_path)\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define your batch analysis parameters</h3>\n",
    "\n",
    "If you have generated nuclei predictions already, make sure to input the same <code>slicing factor</code> you used when generating nuclei predictions. \n",
    "\n",
    "If you have not generated nuclei predictions before, input <code>nuclei_channel</code>, <code>n_tiles</code>, <code>segmentation_type</code> and <code>model_name</code> values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size reduction (downsampling) to improve processing times (slicing, not lossless compression)\n",
    "# Now, in addition to xy, you can downsample across your z-stack\n",
    "slicing_factor_xy = None # Use 2 or 4 for downsampling in xy (None for lossless)\n",
    "slicing_factor_z = None # Use 2 to select 1 out of every 2 z-slices\n",
    "\n",
    "# Define the nuclei and markers of interest channel order ('Remember in Python one starts counting from zero')\n",
    "nuclei_channel = 3\n",
    "\n",
    "# The n_tiles parameter defines the number of tiles the input volume/image will be divided into along each dimension (z, y, x) during prediction. \n",
    "# This is useful for processing large images that may not fit into memory at once.\n",
    "# While tiling can handle memory limitations, chopping the image into smaller chunks increases\n",
    "# the processing time for stitching the predictions back together. \n",
    "# Use n_tiles=(1, 1, 1) if the input volume fits in memory without tiling to minimize processing overhead.\n",
    "n_tiles=(1,4,4)\n",
    "\n",
    "# Segmentation type (\"2D\" or \"3D\"). \n",
    "# 2D takes a z-stack as input, performs MIP (Maximum Intensity Projection) and predicts nuclei from the resulting projection (faster, useful for single layers of cells)\n",
    "# 3D is more computationally expensive. Predicts 3D nuclear volumes, useful for multilayered structures\n",
    "segmentation_type = \"2D\"\n",
    "\n",
    "# Nuclear segmentation model type (\"Stardist\")\n",
    "# Choose your Stardist fine-tuned model (model_name) from stardist_models folder\n",
    "# If no custom model is present, type \"test\" and a standard pre-trained model will be loaded\n",
    "model_name = \"test\" # Type \"test\" if you don't have a custom model trained\n",
    "\n",
    "# Model loading \n",
    "model = get_stardist_model(segmentation_type, name=model_name, basedir='stardist_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define in <code>parameters_per_marker</code> the <code>marker</code> you want to use to define your cell populations of interest, the <code>min_max</code> range of pixel intensity values and the <code>population</code> name.\n",
    "\n",
    "In addition, set the <code>erosion_factor</code> and <code>cytoplasm_dilation_radius</code> for each marker you want to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_max range defines the pixel intensity range within which a cell is considered positive for a marker\n",
    "\n",
    "# erosion_factor sets the amount of erosion that is applied to areas where the marker+ signal colocalizes with nuclear or cytoplasmic signal\n",
    "# The higher the value, the stricter the conditions to consider a nuclei as marker+\n",
    "\n",
    "# cytoplasm_dilation_radius sets the amount of pixels you want to add around the nuclei to simulate the cytoplasm\n",
    "\n",
    "parameters_per_marker = [{\"marker\": \"ki67\", \"min_max_range\": (200, 255), \"population\": \"ki67\", \"erosion_factor\":4, \"cytoplasm_dilation_radius\":0},\n",
    "                      {\"marker\": \"neun\", \"min_max_range\": (50, 115), \"population\": \"neun_low\", \"erosion_factor\":4, \"cytoplasm_dilation_radius\":0},\n",
    "                      {\"marker\": \"neun\", \"min_max_range\": (115, 255), \"population\": \"neun_high\", \"erosion_factor\":4, \"cytoplasm_dilation_radius\":0},\n",
    "                      {\"marker\": \"calbindin\", \"min_max_range\": (65, 255),\"population\": \"calbindin\", \"erosion_factor\":4,  \"cytoplasm_dilation_radius\":2}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Run Batch Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct ROI and nuclei predictions paths from directory_path above\n",
    "roi_path = directory_path / \"ROIs\"\n",
    "nuclei_preds_path =  directory_path / \"nuclei_preds\" / segmentation_type / model_name\n",
    "\n",
    "# Extract the experiment name from the data directory path\n",
    "experiment_id = directory_path.name\n",
    "\n",
    "# Define output folder for results\n",
    "results_folder = Path(\"results\") / experiment_id / segmentation_type / model_name\n",
    "\n",
    "# Create the necessary folder structure if it does not exist\n",
    "try:\n",
    "    os.makedirs(str(results_folder))\n",
    "    print(f\"Output folder created: {results_folder}\")\n",
    "except FileExistsError:\n",
    "    print(f\"Output folder already exists: {results_folder}\")\n",
    "\n",
    "# List of subfolder names\n",
    "try:\n",
    "    roi_names = [folder.name for folder in roi_path.iterdir() if folder.is_dir()]\n",
    "\n",
    "except FileNotFoundError:\n",
    "    roi_names = [\"full_image\"]\n",
    "        \n",
    "print(f\"The following regions of interest will be analyzed: {roi_names}\")\n",
    "\n",
    "for image in tqdm(images):\n",
    "\n",
    "    # Create an empty list to store all stats extracted from each image\n",
    "    stats = []\n",
    "\n",
    "    # Initialize a combined DataFrame with the expected columns for the current image \n",
    "    columns = [\"filename\", \"ROI\", \"label\"] + [param[\"population\"] for param in parameters_per_marker]\n",
    "    combined_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Read image, apply slicing if needed and return filename and img as a np array\n",
    "    img, filename = read_image(image, slicing_factor_xy, slicing_factor_z)\n",
    "\n",
    "    for roi_name in roi_names:\n",
    "\n",
    "        print(f\"\\nAnalyzing ROI: {roi_name}\")\n",
    "\n",
    "        # Read the user defined ROIs, in case of full image analysis generate a label covering the entire image\n",
    "        try:\n",
    "            # Read previously defined ROIs\n",
    "            user_roi = tifffile.imread(roi_path / roi_name / f\"{filename}.tiff\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            # Extract the xy dimensions of the input image \n",
    "            img_shape = img.shape\n",
    "            img_xy_dims = img[-2:]\n",
    "\n",
    "            # Create a label covering the entire image\n",
    "            user_roi = np.ones(img_xy_dims).astype(np.uint8)\n",
    "\n",
    "        # Read previously predicted nuclei labels, if not present generate nuclei predictions and save them\n",
    "        try:\n",
    "            # Read the nuclei predictions per ROI\n",
    "            nuclei_labels = tifffile.imread(nuclei_preds_path / roi_name / f\"{filename}.tiff\")\n",
    "            print(f\"Pre-computed nuclei labels found for {filename}\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Generating nuclei labels for {filename}\")\n",
    "\n",
    "            # If 3D-segmentation input nuclei_img is a 3D-stack\n",
    "            if segmentation_type == \"3D\":\n",
    "                # Slice the nuclei stack\n",
    "                nuclei_img = extract_nuclei_stack(img, nuclei_channel)\n",
    "\n",
    "            # If 2D-segmentation input nuclei_img is a max intensity projection of said 3D-stack\n",
    "            elif segmentation_type == \"2D\":\n",
    "                # Slice the nuclei stack\n",
    "                nuclei_img = extract_nuclei_stack(img, nuclei_channel)\n",
    "                nuclei_img = np.max(nuclei_img, axis=0)\n",
    "\n",
    "            # We will create a mask where roi is greater than or equal to 1\n",
    "            mask = (user_roi >= 1).astype(np.uint8)\n",
    "\n",
    "            # 3D segmentation logic, extend 2D mask across the entire stack volume\n",
    "            if segmentation_type == \"3D\":\n",
    "                # Extract the number of z-slices to extend the mask\n",
    "                slice_nr = img.shape[1]\n",
    "                # Extend the mask across the entire volume\n",
    "                mask = np.tile(mask, (slice_nr, 1, 1))\n",
    "                # Apply the mask to nuclei_img, setting all other pixels to 0\n",
    "                masked_nuclei_img = np.where(mask, nuclei_img, 0)\n",
    "            else:\n",
    "                # Apply the mask to nuclei_img, setting all other pixels to 0\n",
    "                masked_nuclei_img = np.where(mask, nuclei_img, 0)\n",
    "\n",
    "            # Segment nuclei and return labels\n",
    "            nuclei_labels = segment_nuclei(masked_nuclei_img, segmentation_type, model, n_tiles)\n",
    "\n",
    "            # Save nuclei labels as .tiff files to reuse them later\n",
    "            try:\n",
    "                os.makedirs(nuclei_preds_path / roi_name, exist_ok=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating directory {nuclei_preds_path / roi_name}: {e}\")\n",
    "\n",
    "            # Construct path to store\n",
    "            path_to_store = nuclei_preds_path / roi_name / f\"{filename}.tiff\"\n",
    "            print(f\"Saving nuclei labels to {path_to_store}\")\n",
    "            try:\n",
    "                tifffile.imwrite(path_to_store, nuclei_labels)\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving file {path_to_store}: {e}\")\n",
    "\n",
    "        for marker_parameters in parameters_per_marker:\n",
    "\n",
    "            # Extract info from list of dictionaries and open marker_img\n",
    "            marker_name = marker_parameters[\"marker\"]\n",
    "            min_max_range = marker_parameters[\"min_max_range\"]\n",
    "            population = marker_parameters[\"population\"]\n",
    "            erosion_factor = marker_parameters[\"erosion_factor\"]\n",
    "            cytoplasm_dilation_radius = marker_parameters[\"cytoplasm_dilation_radius\"]\n",
    "\n",
    "            print(f\"Analyzing marker/population: {marker_name}/{population}\")\n",
    "\n",
    "            # Retrieve the first and second values (channel and location) of the corresponding tuple in markers\n",
    "            for item in markers:\n",
    "                if item[0] == marker_name:\n",
    "                    marker_channel = item[1]\n",
    "                    location = item[2]\n",
    "                    break  # Stop searching once the marker is found\n",
    "\n",
    "            # Access the corresponding marker intensity image\n",
    "            marker_img = img[marker_channel, :, :, :]\n",
    "\n",
    "            # Select marker positive cell compartments\n",
    "            if location == \"nucleus\":\n",
    "                # Select marker positive nuclei\n",
    "                nuclei_and_marker, eroded_nuclei_and_marker, marker, processed_region_labels = segment_marker_positive_labels(nuclei_labels, marker_img, min_max_range, erosion_factor, segmentation_type)\n",
    "\n",
    "            # Simulate a cytoplasm by growing the nuclei_labels and masking out the inner nucleus\n",
    "            if location == \"cytoplasm\":\n",
    "                if segmentation_type == \"3D\":\n",
    "                    print(f\"Generating {segmentation_type} cytoplasm labels for: {marker_name}\")\n",
    "                    # Simulate a cytoplasm by dilating the nuclei and subtracting the nuclei mask afterwards\n",
    "                    cytoplasm_labels = simulate_cytoplasm_chunked_3d(nuclei_labels, dilation_radius=2, erosion_radius=0, chunk_size=(1, 1024, 1024))\n",
    "\n",
    "                elif segmentation_type == \"2D\":\n",
    "                    print(f\"Generating {segmentation_type} cytoplasm labels for: {marker_name}\")\n",
    "                    # Simulate a cytoplasm by dilating the nuclei and subtracting the nuclei mask afterwards\n",
    "                    cytoplasm_labels = simulate_cytoplasm(nuclei_labels, dilation_radius=2, erosion_radius=0)\n",
    "\n",
    "            # Simulate a cell by growing the nuclei_labels\n",
    "            elif location == \"cell\":\n",
    "                if segmentation_type == \"3D\":\n",
    "                    print(f\"Generating {segmentation_type} cell labels for: {marker_name}\")\n",
    "                    # Simulate a cell volume by dilating the nuclei \n",
    "                    cell_labels = simulate_cell_chunked_3d(nuclei_labels, dilation_radius=2, erosion_radius=0, chunk_size=(1, 1024, 1024))\n",
    "\n",
    "                elif segmentation_type == \"2D\":\n",
    "                    print(f\"Generating {segmentation_type} cell labels for: {marker_name}\")\n",
    "                    # Simulate a cytoplasm by dilating the nuclei and subtracting the nuclei mask afterwards\n",
    "                    cell_labels = simulate_cell(nuclei_labels, dilation_radius=2, erosion_radius=0)\n",
    "\n",
    "            # Store per label results in a dataframe\n",
    "\n",
    "            # Get unique positive labels\n",
    "            #Finds unique values in an array and removes background label (0)\n",
    "            positive_labels = np.unique(processed_region_labels[processed_region_labels != 0])\n",
    "\n",
    "            # Generate the label column with all labels\n",
    "            max_label = nuclei_labels.max()\n",
    "            label_column = np.arange(1, max_label + 1)\n",
    "\n",
    "            # Check if positive_labels is in label_column and set values to True \n",
    "            channel_column = np.isin(label_column, positive_labels)\n",
    "\n",
    "            # Create the DataFrame to hold per label data\n",
    "            df_temp = pd.DataFrame({\n",
    "                \"filename\": [filename] * len(label_column),\n",
    "                \"ROI\": [roi_name] * len(label_column),\n",
    "                'label': label_column,\n",
    "                population: channel_column\n",
    "            })\n",
    "\n",
    "            # Ensure population columns exist in combined_df\n",
    "            for col in [population]:\n",
    "                if col not in combined_df.columns:\n",
    "                    combined_df[col] = False\n",
    "\n",
    "            # Handle potential duplicate columns during merge\n",
    "            combined_df = combined_df.merge(df_temp, on=[\"filename\", \"ROI\", \"label\"], how=\"outer\", suffixes=('', '_dup'))\n",
    "\n",
    "            # Drop duplicate columns while retaining original values from df_temp\n",
    "            for col in combined_df.columns:\n",
    "                if col.endswith('_dup'):\n",
    "                    # Use .where() to retain the original values\n",
    "                    combined_df[col[:-4]] = combined_df[col[:-4]].where(combined_df[col[:-4]].notna(), combined_df[col])\n",
    "\n",
    "                    # Explicitly cast the column to the correct type (e.g., bool or int)\n",
    "                    combined_df[col[:-4]] = combined_df[col[:-4]].astype(bool)  # Change to int if needed\n",
    "                    \n",
    "                    # Drop the duplicate column\n",
    "                    combined_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "            # Define the .csv path\n",
    "            per_filename_csv_path = results_folder / f\"{filename}_per_label_coloc.csv\"\n",
    "\n",
    "            # Save per label data on a per filename basis\n",
    "            combined_df.to_csv(per_filename_csv_path)\n",
    "\n",
    "            # Extract your information of interest\n",
    "            total_nuclei = len(np.unique(nuclei_labels)) - 1\n",
    "            marker_pos_nuclei = len(np.unique(processed_region_labels)) - 1\n",
    "\n",
    "            # Calculate \"%_marker+_cells\" and avoid division by zero errors\n",
    "            try:\n",
    "                perc_marker_pos_cells = (marker_pos_nuclei * 100) / total_nuclei\n",
    "            except ZeroDivisionError:\n",
    "                perc_marker_pos_cells = 0\n",
    "\n",
    "            # Create a dictionary containing all extracted info per masked image\n",
    "            stats_dict = {\n",
    "                        \"filename\": filename,\n",
    "                        \"ROI\": roi_name,\n",
    "                        \"population\": population,\n",
    "                        \"marker\": marker_name,\n",
    "                        \"marker_location\":location,\n",
    "                        \"total_nuclei\": total_nuclei,\n",
    "                        \"marker+_nuclei\": marker_pos_nuclei,\n",
    "                        \"%_marker+_cells\": perc_marker_pos_cells,\n",
    "                        \"nuclei_ch\": nuclei_channel,\n",
    "                        \"marker_ch\": marker_channel,\n",
    "                        \"min_max_avg_int\": min_max_range,\n",
    "                        \"cytoplasm_dilation\":cytoplasm_dilation_radius,\n",
    "                        \"erosion_factor\": erosion_factor,\n",
    "                        \"slicing_factor_xy\": slicing_factor_xy,\n",
    "                        \"slicing_factor_z\": slicing_factor_z\n",
    "                        }\n",
    "\n",
    "            # Append the current data point to the stats_list\n",
    "            stats.append(stats_dict)\n",
    "\n",
    "    # Transform into a dataframe to store it as .csv later\n",
    "    df = pd.DataFrame(stats)\n",
    "\n",
    "    # Define the .csv path\n",
    "    csv_path = results_folder / f\"BP_marker_+_label_coloc.csv\"\n",
    "\n",
    "    # Append to the .csv with new data points each round\n",
    "    df.to_csv(csv_path, mode=\"a\", index=False, header=not os.path.isfile(csv_path))\n",
    "\n",
    "# Show the updated .csv \n",
    "csv_df = pd.read_csv(csv_path)\n",
    "\n",
    "csv_df    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_nuc_stardist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
