{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: /device:GPU:0\n",
      "Device type: GPU\n",
      "GPU model: device: 0, name: NVIDIA GeForce RTX 4090 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<NVIDIA GeForce RTX 4090 Laptop GPU on Platform: NVIDIA CUDA (1 refs)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyclesperanto_prototype as cle\n",
    "import apoc\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "import napari\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from utils_stardist import get_gpu_details, list_images, read_image, maximum_intensity_projection, simulate_cytoplasm_chunked_3d, simulate_cell_chunked_3d, simulate_cytoplasm, simulate_cell\n",
    "\n",
    "get_gpu_details()\n",
    "\n",
    "\n",
    "cle.select_device('RTX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\raw_data\\\\test_data\\\\HI 1  Contralateral Mouse 8  slide 6 Neun Red Calb Green KI67 Magenta 40x technical replica 1.czi',\n",
       " '..\\\\raw_data\\\\test_data\\\\HI 1  Ipsilateral Mouse 8  slide 6 Neun Red Calb Green KI67 Magenta 40x technical replica 1.czi']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the path where your images are stored, you can use absolute or relative paths to point at other disk locations\n",
    "# At this point you should have generate the nuclei label predictions in advance\n",
    "directory_path = Path(\"../raw_data/test_data\")\n",
    "\n",
    "# Define the channels for which you want to train the ObjectClassifier using the following structure:\n",
    "# markers = [(channel_name, channel_nr, cellular_location),(..., ..., ...)]\n",
    "# cellular locations can be \"nucleus\", \"cytoplasm\" or \"cell\" (cell being the sum volume of nucleus and cytoplasm)\n",
    "# Remember in Python one starts counting from 0, so your first channel will be 0\n",
    "# i.e. markers = [(\"ki67\", 0, \"nucleus\"), (\"neun\", 1, \"cell\"), (\"calbindin\", 2, \"cytoplasm\")]\n",
    "\n",
    "markers = [(\"ki67\", 0, \"nucleus\"), (\"neun\", 1, \"cell\"), (\"calbindin\", 2, \"cytoplasm\")]\n",
    "\n",
    "# Iterate through the .czi and .nd2 files in the raw_data directory\n",
    "images = list_images(directory_path)\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Image analyzed: HI 1  Contralateral Mouse 8  slide 6 Neun Red Calb Green KI67 Magenta 40x technical replica 1\n",
      "Original Array shape: (4, 14, 3803, 2891)\n",
      "Compressed Array shape: (4, 14, 3803, 2891)\n"
     ]
    }
   ],
   "source": [
    "# Explore each image to analyze (0 defines the first image in the directory)\n",
    "image = images[0]\n",
    "\n",
    "# Image size reduction (downsampling) to improve processing times (slicing, not lossless compression)\n",
    "# Now, in addition to xy, you can downsample across your z-stack\n",
    "# Try and use the same factors that you applied during your nuclei label prediction and analysis\n",
    "slicing_factor_xy = None # Use 2 or 4 for downsampling in xy (None for lossless)\n",
    "slicing_factor_z = None # Use 2 to select 1 out of every 2 z-slices\n",
    "\n",
    "# Define the nuclei and markers of interest channel order ('Remember in Python one starts counting from zero')\n",
    "nuclei_channel = 3\n",
    "\n",
    "# Segmentation type (\"2D\" or \"3D\"). \n",
    "# 2D takes a z-stack as input, performs MIP (Maximum Intensity Projection) and predicts nuclei from the resulting projection (faster, useful for single layers of cells)\n",
    "# 3D is more computationally expensive. Predicts 3D nuclear volumes, useful for multilayered structures\n",
    "segmentation_type = \"3D\"\n",
    "\n",
    "# Nuclear segmentation model type (\"Stardist\")\n",
    "# Choose your Stardist fine-tuned model (model_name) from stardist_models folder\n",
    "model_name = \"MEC0.1\"\n",
    "\n",
    "# Type the ROI name you wish to load (by default it is \"full_image\")\n",
    "# It is recommended to traom the ObjectClassifier based on the full imag\n",
    "roi_name = \"full_image\"\n",
    "\n",
    "# Choose the channel you want to use to train the ObjectClassifier for:\n",
    "marker_name = \"neun\"\n",
    "\n",
    "# Read image, apply slicing if needed and return filename and img as a np array\n",
    "img, filename = read_image(image, slicing_factor_xy, slicing_factor_z)\n",
    "# Construct ROI and nuclei predictions paths from directory_path above\n",
    "roi_path = directory_path / \"ROIs\"\n",
    "nuclei_preds_path =  directory_path / \"nuclei_preds\" / segmentation_type / model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the first and second values (channel and location) of the corresponding tuple in markers\n",
    "for item in markers:\n",
    "    if item[0] == marker_name:\n",
    "        marker_channel = item[1]\n",
    "        location = item[2]\n",
    "        break  # Stop searching once the marker is found\n",
    "\n",
    "# Close any previous Napari instances that are open, ignore WARNING messages\n",
    "try:\n",
    "    viewer.close()\n",
    "\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "except RuntimeError:\n",
    "    pass\n",
    "\n",
    "if segmentation_type == \"3D\":\n",
    "\n",
    "    # Load Napari viewer\n",
    "    viewer = napari.Viewer(ndisplay=2)\n",
    "    # Slice marker stack\n",
    "    marker_img = img[marker_channel]\n",
    "    viewer.add_image(marker_img)\n",
    "\n",
    "elif segmentation_type == \"2D\":\n",
    "\n",
    "    # Generate maximum intensity projection \n",
    "    img = maximum_intensity_projection(img)\n",
    "    # Load Napari viewer\n",
    "    viewer = napari.Viewer(ndisplay=2)\n",
    "    # Slice marker stack\n",
    "    marker_img = img[marker_channel]\n",
    "    viewer.add_image(marker_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computed nuclei labels found for HI 1  Contralateral Mouse 8  slide 6 Neun Red Calb Green KI67 Magenta 40x technical replica 1\n",
      "Generating 3D cell labels for: neun\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'labels' at 0x1e9dc8f4a60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load nuclei labels and transform them into cell or cytoplasm labels if necessary\n",
    "try:\n",
    "    # Read the nuclei predictions per ROI\n",
    "    labels = tifffile.imread(nuclei_preds_path / roi_name / f\"{filename}.tiff\")\n",
    "    print(f\"Pre-computed nuclei labels found for {filename}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Nuclei labels for filename: {filename} ROI: {roi_name} not found. Please generate them using 002_BP_Predict_nuclei_labels.ipynb\")\n",
    "\n",
    "if location == \"cytoplasm\":\n",
    "    if segmentation_type == \"3D\":\n",
    "        print(f\"Generating {segmentation_type} cytoplasm labels for: {marker_name}\")\n",
    "        # Simulate a cytoplasm by dilating the nuclei and subtracting the nuclei mask afterwards\n",
    "        labels = simulate_cytoplasm_chunked_3d(labels, dilation_radius=2, erosion_radius=0, chunk_size=(1, 1024, 1024))\n",
    "\n",
    "    elif segmentation_type == \"2D\":\n",
    "        print(f\"Generating {segmentation_type} cytoplasm labels for: {marker_name}\")\n",
    "        # Simulate a cytoplasm by dilating the nuclei and subtracting the nuclei mask afterwards\n",
    "        labels = simulate_cytoplasm(labels, dilation_radius=2, erosion_radius=0)\n",
    "\n",
    "elif location == \"cell\":\n",
    "    if segmentation_type == \"3D\":\n",
    "        print(f\"Generating {segmentation_type} cell labels for: {marker_name}\")\n",
    "        # Simulate a cell volume by dilating the nuclei \n",
    "        labels = simulate_cell_chunked_3d(labels, dilation_radius=2, erosion_radius=0, chunk_size=(1, 1024, 1024))\n",
    "\n",
    "    elif segmentation_type == \"2D\":\n",
    "        print(f\"Generating {segmentation_type} cell labels for: {marker_name}\")\n",
    "        # Simulate a cytoplasm by dilating the nuclei and subtracting the nuclei mask afterwards\n",
    "        labels = simulate_cell(labels, dilation_radius=2, erosion_radius=0)\n",
    "\n",
    "viewer.add_labels(labels, opacity=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Annotation in Napari</h2>\n",
    "\n",
    "Create a new Labels layers and draw on top of each label according to the class you want to assign to them. In this example we have cells negative for Neun (label 1), low Neun (label 2) and high Neun cells (label 3). Once you are done proceed to run the next cells.\n",
    "\n",
    "<video controls>\n",
    "  <source src=\"../assets/apoc_oc_annotation.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder structure to store resulting Object Classifiers\n",
    "apoc_path = Path(\"APOC_ObjectClassifiers\") / directory_path.name\n",
    "try:\n",
    "    os.makedirs(apoc_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Define features on which the classifier will be trained on (see train -help for full list of features)\n",
    "features = 'min_intensity,max_intensity,sum_intensity,mean_intensity,standard_deviation_intensity'\n",
    "\n",
    "cl_filename = f\"./{apoc_path}/ObjClass_{segmentation_type}_ch{marker_channel}.cl\"\n",
    "\n",
    "# Create an object classifier\n",
    "apoc.erase_classifier(cl_filename) # Delete it if it was existing before\n",
    "classifier = apoc.ObjectClassifier(cl_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not happy with the classifier go back to Napari and edit the \"Labels\" layer with a few more annotations, then run the cells below to fetch your modifications, train the classifier again and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adiez_cmic\\miniforge3\\envs\\brain_nuc_stardist\\lib\\site-packages\\apoc\\_pixel_classifier.py:107: UserWarning: Cannot continue training if it wasn't trained before. Will train from scratch instead.\n",
      "  warnings.warn(\"Cannot continue training if it wasn't trained before. Will train from scratch instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_intensity': 0.11734732285229599,\n",
       " 'max_intensity': 0.08846625807667363,\n",
       " 'sum_intensity': 0.23350138516650665,\n",
       " 'mean_intensity': 0.38762326688261955,\n",
       " 'standard_deviation_intensity': 0.1730617670219043}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect user input from Napari and train/retrain the ObjectClasifier based on it\n",
    "user_input = user_input = viewer.layers[\"Labels\"].data\n",
    "\n",
    "# Train or retrain your classifier\n",
    "classifier.train(features, labels, user_input, marker_img, continue_training=True)\n",
    "\n",
    "# Print the weights of each feature in the decision process\n",
    "classifier.feature_importances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'result' at 0x1e9d186a170>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apoc_path = Path(\"APOC_ObjectClassifiers\") / directory_path.name\n",
    "cl_filename = f\"./{apoc_path}/ObjClass_{segmentation_type}_ch{marker_channel}.cl\"\n",
    "\n",
    "# Reload the classifier from disc to use the latest version\n",
    "classifier = apoc.ObjectClassifier(cl_filename)\n",
    "\n",
    "# Determine object classification\n",
    "result = classifier.predict(labels, marker_img)\n",
    "\n",
    "# Show the result\n",
    "viewer.add_labels(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 5.309164698861625, 2: 42.170361358465414, 3: 113.86806458350068}\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average intensity of a marker in each of the classified populations\n",
    "# Treat all 'labels' holding the same value as a mask\n",
    "\n",
    "# Extract the number of different populations ignoring the background\n",
    "unique_masks = np.unique(result).tolist()\n",
    "unique_masks.remove(0)  # Remove background (0)\n",
    "\n",
    "# Initialize an empty dictionary to store the average intensity values for each mask of labels\n",
    "mean_intensities = {}\n",
    "\n",
    "# Calculate the average intensity of a marker in each of the classified populations\n",
    "for mask_value in unique_masks:\n",
    "    mask = cle.pull(result) == mask_value  # Create a boolean mask\n",
    "    mean_intensity = marker_img[mask].mean() if np.any(mask) else 0 # Calculate average intensity\n",
    "    mean_intensities[mask_value] = mean_intensity # Store the values\n",
    "\n",
    "# Sort dictionary from min to max mean_intensity\n",
    "sorted_mean_intensities = dict(sorted(mean_intensities.items(), key=lambda item: item[1]))\n",
    "\n",
    "print(sorted_mean_intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster alternative with regionprops and pandas\n",
    "from skimage import measure\n",
    "\n",
    "# Calculate the average intensity of a marker in each of the classified populations\n",
    "regionprops = measure.regionprops_table(cle.pull(result), marker_img, properties=('label', 'mean_intensity'))\n",
    "\n",
    "# Transform the result into a Dataframe and sort by mean_intensity\n",
    "regionprops_df = pd.DataFrame(regionprops)\n",
    "regionprops_df = regionprops_df.sort_values(by='mean_intensity', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Extract the order of the labels according to mean_intensity values\n",
    "sorted_mean_intensities = regionprops_df['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['low', 'med', 'high']\n"
     ]
    }
   ],
   "source": [
    "# Assign subpopulation suffixes based on the number of subpopulations (masks > 0) present\n",
    "if len(sorted_mean_intensities) == 1:\n",
    "    subpopulations = ['']\n",
    "\n",
    "elif len(sorted_mean_intensities) == 2:\n",
    "    subpopulations = ['low', 'high']\n",
    "\n",
    "elif len(sorted_mean_intensities) == 3:\n",
    "    subpopulations = ['low', 'med', 'high']\n",
    "\n",
    "elif len(sorted_mean_intensities) > 3:\n",
    "    subpopulations = list(range(1, len(sorted_mean_intensities) + 1))\n",
    "\n",
    "print(subpopulations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mean_intensity</th>\n",
       "      <th>subpopulation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>42.170361</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>113.868065</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  mean_intensity subpopulation\n",
       "0      2        0.000000           low\n",
       "1      1       42.170361           med\n",
       "2      3      113.868065          high"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign subpopulation suffix to each label according to the mean_intensity values (from min to max)\n",
    "regionprops_df['subpopulation'] = subpopulations\n",
    "\n",
    "regionprops_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "low\n",
      "1\n",
      "med\n",
      "3\n",
      "high\n"
     ]
    }
   ],
   "source": [
    "for label in regionprops_df['label']:\n",
    "\n",
    "    # Retrieve subpopulation definition\n",
    "    subpopulation = regionprops_df.loc[regionprops_df['label'] == label, 'subpopulation'].iloc[0]\n",
    "\n",
    "    print(label)\n",
    "    print(subpopulation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_nuc_stardist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
